====tradeoffs
====databases
====properties
====debugging
====kubernetes
====kubernetes_debug
====kubernetes_monitoring_logging
====kubernetes_deployments

====incus_usage

====tradeoffs
https://www.docker.com/blog/do-you-really-need-microservices/
from lower complexity/stricter coupling to bigger agility/harder to run
* monolith / marco services
  + monolithic application on app server running multiple service domains
* service-oriented-architecture / miniservices/macroservices
  + app server and runtimes with data store for services domains
* ?? / microservices
  + only runtimes with data store for each feature
prerequisites:
- dedicated service ownership
- mature CI/CD
- robust monitoring
- scale that justifies the operational overhead
  + operational cost of infra
  + dev productivity drain: constantly check for partial failure (missing integrity)
  + test + deployment complexity: integration and e2e test across service boundaries, test suite becomes bottleneck
    o partial updated systems are difficult to recover from
  + data consistency across service boundaries
    o multi-step workflows with rollback logic xor eventual consistency xor extra code to undo partial failures
    o core pain points: data duplication, correctness challenges, and transactional complexity
  + compounding effect
    o ripple effect of operational overhead
alternatives:
* modular monolith with well-interfaces
* Service-Oriented Architecture with larger, domain-driven services
  + communication via Enterprise Service Bus (ESB)

====properties
1 idempotency
2 consistency
3 backpressure
4 observability
5 fault-tolerance
6 service discovery
(less often)
7 consensus
8 replication

====sources
https://github.com/basilysf1709/distributed-systems

====problems
debugging VMs is yet another tool to learn

====future
https://www.macchaffee.com/blog/2024/the-next-platform/
app needed
* can accept tcp + http from internet
* can store state which is highly-available, secure and backed-up
* can manage app configs and secrets
* can collect logs, metrics and other debug infos from app
* can easily deploy new versions of app
infra needed
* custom hw/network/security
* edge connectivity
* compat with legacy apps
* can run on-premise
* affordable at scale
unclear parts:
* core use cases of Kubernetes
  - 1. gobble together unreliable applications
  - 2. do on-demand scaling
    2.1 without performance optimizations of an application or
    2.2 buying/scaling infrastructure
* reasonable implementation and configuration complexity?
* few advantages of self-hosting for optimizing cross-pod 1. bandwidth or 2. latency guarantees
  - less often used/likely: hard real-time capable control solutions
  - soft real-time capable control solutions
  - better time sync
  - meaningful time diagnostics to understand network<->application
  https://community.fs.com/encyclopedia/network-slicing.html
* make more system data part of the resource management scheduling plan (when
  what device can serve how much traffic and what the network prediction is)
  => simpler to use and portable SLURM with real-time stuff usable for cloud
  => see "HPC cluster management software"
* maybe vertical scaling always means giving up (high) control on latency and
  resource efficiency (to a degree) or having (unreasonable) complex system
  configurations?

====scheduler_control
* kubernetes as framework to integrate and control containers of own and hosted solutions

TODO
====kubernetes
* reason 1 scale vertically applications on demand
* reason 2 reduce operator cost by declarative configuration
* tradeoff: no hard latency or time-critical control, no security model (configs + hacks leaving open many attack vectors)
* go code with garbage collection
* https://medium.com/@arschles/go-experience-report-generics-in-kubernetes-25da87430301
* https://pkg.go.dev/k8s.io/apimachinery/pkg/runtime
+ scheduler
+ how to break it
+ diagnostics
+ lxc containers
https://github.com/omissis/zho/
* kubernetes 1 million nodes active nodes challenge https://bchess.github.io/k8s-1m/
* distributed fs https://github.com/seaweedfs/seaweedfs

====kubernetes_debug


====kubernetes_monitoring_logging
https://kubernetes.io/docs/tasks/debug/
https://middleware.io/blog/kubernetes-troubleshooting-techniques/
https://kubernetes.io/docs/tasks/debug/debug-cluster/

====kubernetes_deployments
https://www.ionos.at/digitalguide/server/konfiguration/kubernetes-deployment/
https://kubernetes.io/docs/concepts/workloads/controllers/deployment/


====nix/lix for linux kernel experiments/stuff
====how to attach debugger over network over kubernetes

====ideas
idea summarize videos from https://www.youtube.com/@AntonPutra/videos
for understanding what those things are and how
* AWS
* minikube (simple test environment)
* nginx
* docker
* terraform
* kafka
* prometheus
* app monitoring 4 golden signals

idea attacks and worst cases (single points of failures like bugs in tools to monitor bugs etc)
idea analysis/videos of overhead of kubernetes for understanding tradeoffs
idea analysis and debugging tools of kubernetes
minikube tutorial https://www.youtube.com/watch?v=qBudNa-j7as
intro to kubernetes https://www.youtube.com/watch?v=OS8S0FcrgvU
structuring terraform projects https://www.youtube.com/watch?v=nMVXs8VnrF4
more concrete
idea how much complexity one can manage on your own
idea automatic attaching a debugger for ssh into machine and attach
idea kernel debugging possible and how? should be simple ssh/separate login,
ideally something better than ssh supported on the platform

====databases
idea list databases for distributed use cases
idea list databases for not losing data by type TM
"Use of Time in Distributed Databases - don't fall behind the times" by Murate Demirbas

====shared_memory
??

====network_queue
Network queue implementation withvendor lock-in:
* AMQP 0-9-1 (Advanced Message Queuing Protocol)
* NATS
* Pulsar - Apache Pulsar adapter
* SQS - Amazon SQS adapter
* Kafka - Apache Kafka adapter
* Valkey - Valkey NoSQL data store adapter
* Beanstalkd - Beanstalkd - simple, fast work queue adapter
Network queue implementation without vendor lock-in:
* develop own QUEUE API
* provide adapters for  different network work queue protocols

====uptime_downtime
formula:

uptime       |  downtime       | requirement
99.00000 %   |  3d 15h 39m     |
99.90000 %   |      8h 45m 56s | single-region, basic failover
99.99000 %   |         52m 15s | multi-region, health checks, automatic failover
99.99900 %   |          5m 15s | every layer redundancy, real-time monitoring, active-active deployment
99.99990 %   |             31s | chaos engineering, automated canary deployments, sophisticated traffic management
99.99999 %   |        3.1536ss | likely direct physical connection of limited participants necessary, static routing (estimation)
99.999999%   |         3*10-1s | soft real-time operating kernel of involved systems (estimation)
99.9999999%  |         3*10-2s | hard real-time operating kernel of involved systems (estimation)
99.99999999% |         3*10-3s | hard-ware only (estimation very unclear)

https://github.com/palvaro/CSE232-Spring23
* Graduate Distributed Systems

====debugging
=concurrency
https://www.youtube.com/watch?v=_9B__0S21y8
https://videopundits.com/watch/shared/tackling-concurrency-bugs-with-tla-by-hillel-wayne

====incus_usage
TODO

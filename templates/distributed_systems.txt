====tradeoffs
====databases
====properties
====debugging
====kubernetes
====kubernetes_debug
====kubernetes_monitoring_logging
====kubernetes_deployments
====storage

====incus_usage
====Infrastructure_as_Code
====opentofu

https://github.com/donlon/cloudflare-error-page

====tradeoffs
https://www.docker.com/blog/do-you-really-need-microservices/
from lower complexity/stricter coupling to bigger agility/harder to run
* monolith / marco services
  + monolithic application on app server running multiple service domains
* service-oriented-architecture / miniservices/macroservices
  + app server and runtimes with data store for services domains
* ?? / microservices
  + only runtimes with data store for each feature
prerequisites:
- dedicated service ownership
- mature CI/CD
- robust monitoring
- scale that justifies the operational overhead
  + operational cost of infra
  + dev productivity drain: constantly check for partial failure (missing integrity)
  + test + deployment complexity: integration and e2e test across service boundaries, test suite becomes bottleneck
    o partial updated systems are difficult to recover from
  + data consistency across service boundaries
    o multi-step workflows with rollback logic xor eventual consistency xor extra code to undo partial failures
    o core pain points: data duplication, correctness challenges, and transactional complexity
  + compounding effect
    o ripple effect of operational overhead
alternatives:
* modular monolith with well-interfaces
* Service-Oriented Architecture with larger, domain-driven services
  + communication via Enterprise Service Bus (ESB)

====properties
1 idempotency
2 consistency
3 backpressure
4 observability
5 fault-tolerance
6 service discovery
(less often)
7 consensus
8 replication

====sources
https://github.com/basilysf1709/distributed-systems

====problems
debugging VMs is yet another tool to learn

====future
https://www.macchaffee.com/blog/2024/the-next-platform/
app needed
* can accept tcp + http from internet
* can store state which is highly-available, secure and backed-up
* can manage app configs and secrets
* can collect logs, metrics and other debug infos from app
* can easily deploy new versions of app
infra needed
* custom hw/network/security
* edge connectivity
* compat with legacy apps
* can run on-premise
* affordable at scale
unclear parts:
* core use cases of Kubernetes
  - 1. make reasonably stateless applications more reliable
    - reasonble stateless means not many database accesses needed for state (data+checkpoints,recovery)
      to make kubernetes logic happy (requires stateless applications/state being external)
    - handles hardware/software outage
  - 2. workaround poor/insufficient infrastructure maintenance
  - 3. do on-demand scaling
    3.1 without performance optimizations of an application or
    3.2 buying/scaling infrastructure
    => user control of hypervisor library + state handling libraries + orchestration library
    + security handling library needed. tooling unification and APIs needed to
    offer/write inter-operable library.
    => cheap and easy to use local hardware needed to build local clusters.

* reasonable implementation and configuration complexity?
* few advantages of self-hosting for optimizing cross-pod 1. bandwidth or 2. latency guarantees
  - less often used/likely: hard real-time capable control solutions
  - soft real-time capable control solutions
  - better time sync
  - meaningful time diagnostics to understand network<->application
  https://community.fs.com/encyclopedia/network-slicing.html
* make more system data part of the resource management scheduling plan (when
  what device can serve how much traffic and what the network prediction is)
  => simpler to use and portable SLURM with real-time stuff usable for cloud
  => see "HPC cluster management software"
* maybe vertical scaling always means giving up (high) control on latency and
  resource efficiency (to a degree) or having (unreasonable) complex system
  configurations?

====scheduler_control
* kubernetes as framework to integrate and control containers of own and hosted solutions

====kubernetes
* good at handling relative stateless applications
* bad at handling (very) stateful applications
  - every state recovery [backtrack, checkpoint restore] needs database pass
  - default/optimized to handle stateless applications, so no user-provided state management system
* security: runs in own VPN and applications in pods are isolated; nodes share same security context
  - easy to take over cluster, if pods are compromised
  - there are hard to maintain security solutions on top
  - no custom Kernel/OS architecture enforcing a modern security model, k8 builds on Linux primitives
* reason 1 on demand vertical and horizontal scaling of applications
* reason 2 reduce operator cost by declarative configuration
* tradeoff: no hard latency or time-critical control, no security model (configs + hacks leaving open many attack vectors)
  - security model: each cluster has its own VPN, default Linux containers, no VM
  - https://research.checkpoint.com/2026/voidlink-the-cloud-native-malware-framework/
  - looks like bad things might happen with kubernetes, docker
    => dependency attacks very common
    => point of security tools to prevent access escalation (and follow-up)
    and communication to web (with follow-up)
    => Kubernetes/docker have weak tools to do that,
    so attack frameworks might become very lucrative.
* go code with garbage collection
* https://medium.com/@arschles/go-experience-report-generics-in-kubernetes-25da87430301
* https://pkg.go.dev/k8s.io/apimachinery/pkg/runtime
+ scheduler
+ how to break it
+ diagnostics
+ lxc containers
https://github.com/omissis/zho/
* kubernetes 1 million nodes active nodes challenge https://bchess.github.io/k8s-1m/
* distributed fs https://github.com/seaweedfs/seaweedfs

Pod Security Admission (PSA) model
* verifies whether pods comply with namespace security requirements
  - baseline, restricted, privileged
  - warning/audit/enforce mode
  - production workloads should be always restricted (except for system services)
Custom Resource Definitions (CRDs)
* automation, security compliance, mapping industriy+business logic

https://www.qovery.com/blog/northflank-alternatives
* Mirantis Kubernetes Engine uses https://github.com/k0sproject/rig, which is
  a Kubernetes vendor-specific infra tool.
  + trade-offs sound good, few superflous complexity in practice
  + instead: vendor lockin
* everything in Kubernetes wants yaml or a yaml generator (helm or alternatives)
  - kustomize is alternative, but too stupid

====kubernetes_debug
* no direct hardware access (sitting atop of hypervisor talking to management API,
  not controlling hardware) makes debugging low level problems tricky
* complexity makes debugging tricky
* troubleshooting network or (more rarely) hardware problems without hardware access
  of course tricky
* debugging based on cheap metrics, not heavy string log indexing + searches, see Grafana stack
* problematic:
  - 1 offers unbounded complexity
  - 2 no unified (remote debugging) tooling
  - 3 no best practices for vendor + security + cost deployment validation / monitoring

====kubernetes_debug
TODO

====kubernetes_monitoring_logging
https://kubernetes.io/docs/tasks/debug/
https://middleware.io/blog/kubernetes-troubleshooting-techniques/
https://kubernetes.io/docs/tasks/debug/debug-cluster/

====kubernetes_deployments
https://www.ionos.at/digitalguide/server/konfiguration/kubernetes-deployment/
https://kubernetes.io/docs/concepts/workloads/controllers/deployment/
default kubernetes has no
* 1 ingress/gateway [kong, envoy]
* 2 secret management+rolling
* 3 external DNS [TODO]
* 4 gitlab agent
* 5 grafana/cockpit(mimi+tempo+loki)+alloy for metrics; Graylog(legacy applications)
* 6 kube state matrix (scaleway has cluster monitoring f√ºr pods und deployments)
* 7 version checker [argo can replace that]
* 8 egress [kong maybe can do wireguard]
* 9 alert manager (complex setup) [by vendor like scaleway]
* 10 managed postgresql; postgresql operator [by vendor like scaleway]
  - when to do migrations
  - rollbacks argo rollouts<->k8 glue code
  - rollbacks/checkpoints

====storage
MinIO replacement options
* S3Proxy
* RustFS (alpha)
* SeaweedFS
* Zenko CloudServer (okish)
* Garage (complex config)
* Apache Ozone (complex config)
* Ceph Object Gateway (heavy dependency)

====nix/lix for linux kernel experiments/stuff
====how to attach debugger over network over kubernetes

====ideas
idea summarize videos from https://www.youtube.com/@AntonPutra/videos
for understanding what those things are and how
* AWS
* minikube (simple test environment)
* nginx
* docker
* terraform
* kafka
* prometheus
* app monitoring 4 golden signals

idea attacks and worst cases (single points of failures like bugs in tools to monitor bugs etc)
idea analysis/videos of overhead of kubernetes for understanding tradeoffs
idea analysis and debugging tools of kubernetes
minikube tutorial https://www.youtube.com/watch?v=qBudNa-j7as
intro to kubernetes https://www.youtube.com/watch?v=OS8S0FcrgvU
structuring terraform projects https://www.youtube.com/watch?v=nMVXs8VnrF4
more concrete
idea how much complexity one can manage on your own
idea automatic attaching a debugger for ssh into machine and attach
idea kernel debugging possible and how? should be simple ssh/separate login,
ideally something better than ssh supported on the platform

====databases
idea list databases for distributed use cases
idea list databases for not losing data by type TM
"Use of Time in Distributed Databases - don't fall behind the times" by Murate Demirbas

====shared_memory
??

====network_queue
Network queue implementation withvendor lock-in:
* AMQP 0-9-1 (Advanced Message Queuing Protocol)
* NATS
* Pulsar - Apache Pulsar adapter
* SQS - Amazon SQS adapter
* Kafka - Apache Kafka adapter
* Valkey - Valkey NoSQL data store adapter
* Beanstalkd - Beanstalkd - simple, fast work queue adapter
Network queue implementation without vendor lock-in:
* develop own QUEUE API
* provide adapters for  different network work queue protocols

====uptime_downtime
formula:

uptime       |  downtime       | requirement
99.00000 %   |  3d 15h 39m     |
99.90000 %   |      8h 45m 56s | single-region, basic failover
99.99000 %   |         52m 15s | multi-region, health checks, automatic failover
99.99900 %   |          5m 15s | every layer redundancy, real-time monitoring, active-active deployment
99.99990 %   |             31s | chaos engineering, automated canary deployments, sophisticated traffic management
99.99999 %   |        3.1536ss | likely direct physical connection of limited participants necessary, static routing (estimation)
99.999999%   |         3*10-1s | soft real-time operating kernel of involved systems (estimation)
99.9999999%  |         3*10-2s | hard real-time operating kernel of involved systems (estimation)
99.99999999% |         3*10-3s | hard-ware only (estimation very unclear)

https://github.com/palvaro/CSE232-Spring23
* Graduate Distributed Systems

====debugging
=concurrency
https://www.youtube.com/watch?v=_9B__0S21y8
https://videopundits.com/watch/shared/tackling-concurrency-bugs-with-tla-by-hillel-wayne

====incus_usage
TODO

"Redbench: Workload Synthesis From Cloud Traces"
* https://github.com/DataManagementLab/Redbench
"PystachIO: Efficient Distributed GPU Query Processing with PyTorch over Fast Networks & Fast Storage"
* Tensor computation runtimes (TCRs), such as PyTorch, accelerate analytical workloads
* distributed GPU-based query processing

====Infrastructure_as_Code
Infrastructure_as_Code (IaC)
https://spacelift.io/blog/infrastructure-as-code-tools
aka config for VMs and sandboxes across platforms with behavior integration
* Spacelift
* Terraform
* OpenTofu
* Terragrunt
* Pulumi
* AWS CloudFormation
* Azure ARM
* Google CDM
* Kubernetes Operators
* Crossplane
* Ansible
* Chef
* Salt
* Puppet
* Vagrant
* AWS CDK

====opentofu
https://www.scaleway.com/en/docs/terraform/quickstart/
https://search.opentofu.org/provider/opentofu/scaleway/latest
https://www.scaleway.com/en/docs/tutorials/manage-instances-with-terraform-and-functions/
https://www.scaleway.com/en/docs/tutorials/use-cockpit-with-terraform/
https://www.scaleway.com/en/docs/cockpit/concepts/#cockpit
https://controlmonkey.io/resource/opentofu-errors-guide/

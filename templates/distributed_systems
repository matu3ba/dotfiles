
fault-tolerance?
consistency?
service discovery?

====sources
https://github.com/basilysf1709/distributed-systems

====problems
debugging VMs is yet another tool to learn

====future
https://www.macchaffee.com/blog/2024/the-next-platform/
app needed
* can accept tcp + http from internet
* can store state which is highly-available, secure and backed-up
* can manage app configs and secrets
* can collect logs, metrics and other debug infos from app
* can easily deploy new versions of app
infra needed
* custom hw/network/security
* edge connectivity
* compat with legacy apps
* can run on-premise
* affordable at scale
unclear parts:
* core use cases of Kubernetes
  - 1. gobble together unreliable applications
  - 2. do on-demand scaling
    2.1 without performance optimizations of an application or
    2.2 buying/scaling infrastructure
* reasonable implementation and configuration complexity?
* few advantages of self-hosting for optimizing cross-pod 1. bandwidth or 2. latency guarantees
  - less often used/likely: hard real-time capable control solutions
  - soft real-time capable control solutions
  - better time sync
  - meaningful time diagnostics to understand network<->application
  https://community.fs.com/encyclopedia/network-slicing.html
* make more system data part of the resource management scheduling plan (when
  what device can serve how much traffic and what the network prediction is)
  => simpler to use and portable SLURM with real-time stuff usable for cloud
  => see "HPC cluster management software"
* maybe vertical scaling always means giving up (high) control on latency and
  resource efficiency (to a degree) or having (unreasonable) complex system
  configurations?

====scheduler_control
* kubernetes as framework to integrate and control containers of own and hosted solutions

TODO
====Kubernetes
* reason 1 scale vertically applications on demand
* reason 2 reduce operator cost by declarative configuration
* tradeoff: no hard latency or time-critical control
* go code with garbage collection
* https://medium.com/@arschles/go-experience-report-generics-in-kubernetes-25da87430301
* https://pkg.go.dev/k8s.io/apimachinery/pkg/runtime
+ scheduler
+ how to break it
+ diagnostics
+ lxc containers
https://github.com/omissis/zho/

====nix/lix for linux kernel experiments/stuff
====how to attach debugger over network over kubernetes

====ideas
idea summarize videos from https://www.youtube.com/@AntonPutra/videos
for understanding what those things are and how
* AWS
* minikube (simple test environment)
* nginx
* docker
* terraform
* kafka
* prometheus
* app monitoring 4 golden signals

idea attacks and worst cases (single points of failures like bugs in tools to monitor bugs etc)
idea analysis/videos of overhead of kubernetes for understanding tradeoffs
idea analysis and debugging tools of kubernetes
minikube tutorial https://www.youtube.com/watch?v=qBudNa-j7as
intro to kubernetes https://www.youtube.com/watch?v=OS8S0FcrgvU
structuring terraform projects https://www.youtube.com/watch?v=nMVXs8VnrF4
more concrete
idea how much complexity one can manage on your own
idea automatic attaching a debugger for ssh into machine and attach
idea kernel debugging possible and how? should be simple ssh/separate login,
ideally something better than ssh supported on the platform

====databases
idea list databases for distributed use cases
idea list databases for not losing data by type TM

====shared_memory
??

====network_queue
Network queue implementation withvendor lock-in:
* AMQP 0-9-1 (Advanced Message Queuing Protocol)
* NATS
* Pulsar - Apache Pulsar adapter
* SQS - Amazon SQS adapter
* Kafka - Apache Kafka adapter
* Valkey - Valkey NoSQL data store adapter
* Beanstalkd - Beanstalkd - simple, fast work queue adapter
Network queue implementation without vendor lock-in:
* develop own QUEUE API
* provide adapters for  different network work queue protocols

====uptime_downtime
formula:

uptime       |  downtime       | requirement
99.00000 %   |  3d 15h 39m     |
99.90000 %   |      8h 45m 56s | single-region, basic failover
99.99000 %   |         52m 15s | multi-region, health checks, automatic failover
99.99900 %   |          5m 15s | every layer redundancy, real-time monitoring, active-active deployment
99.99990 %   |             31s | chaos engineering, automated canary deployments, sophisticated traffic management
99.99999 %   |        3.1536ss | likely direct physical connection of limited participants necessary, static routing (estimation)
99.999999%   |         3*10-1s | soft real-time operating kernel of involved systems (estimation)
99.9999999%  |         3*10-2s | hard real-time operating kernel of involved systems (estimation)
99.99999999% |         3*10-3s | hard-ware only (estimation very unclear)

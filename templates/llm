====llms
====artifacts
====known_to_work_use_cases
====visualization

====llms
* fast selection of models via https://github.com/jedisct1/inferswitch
* reasoning about llms https://transformer-circuits.pub/2025/attribution-graphs/methods.html

====artifacts
https://ea.rna.nl/2024/05/27/when-chatgpt-summarises-it-actually-does-nothing-of-the-kind/
* sumarizing
  - parameters from training material
    o subject is well-represented by the parameters => parameters dominate the
    summary more and the actual text you want to summarise influences the summary
    less
    o bad in making specific summaries of a subject that is widespread
  - context (prompts and answers until now in chat) including the text given to summarise
    o context very small => little influence, so result dominated by parameters
    o context large enough and subject not well-represented by params =>
    text to summarize dominates results resulting in "text shortening", not
    true summarizing
  - no intelligence involved, query machine with context for processing

====known_to_work_use_cases
given known probability distribution(s) and sufficient handling of edge cases (controlled environment or enumeratable enough)
* 1. copy-paste/use common optimal learned goal
  - claude for more brute-force like editing and local simplifications
  - coderabbitai for context-aware/learned analysis to review code
* 2. automate calibration-like tasks
  - diy llms (+ textual frontend, progress etc)
* 3. basic overview stuff not to be trusted/needs validation
  - deepseek, chatgpt, gemini

any automation system can only be as good as the (formal) semantics encoding
it, so dont expect much without (formal) encoding of meanings or copy-paste
solution.

====visualization
https://bbycroft.net/llm

Any coding standard which insists on syntactic clarity at the expense of
algorithmic clarity should be rewritten.

HACK
TODO
FIXME

c/c++
cpplint, flawfinder, clang-tidy
hefty dependency: oclint

`clang-tidy -checks='bugprone-*,cert-*,clang-analyzer-*,cppcoreguidelines-*,hicpp-*' file.c -- [clang[++]|gcc|g++]-flags`
`hicpp-*` occasionally must be disabled.
`misc-*` opinionated
`modernize-*` bad for C interop (use 0 instead of nullptr to interop with C)
`performance-*` depends
`portability-*` depends
`readability-*` opinionated

isOverlapping( for [start,end) intervals]:
assume: intervals
       | |
     | |
dont overlap, xa < xb and ya < yb
      ya       yb
      |--------|
xa |--|xb
   |----|
         |----|
ya > xa => ya - xa < xb - xa ?
else    => xa < yb ?

intersection( for [start,end) intervals]:
[max(xa,ya),min(xb,yb)]

With above formula, detecting overlaps of a recurring timer interval and an absolute one:
Given fixed interval [    ]  and variable interval [  ]
                     ya   yb                       xa xb
1. overlap, if ya > xa => ya - xa < xb - xa ?
2.             ya <=xa => xa < yb ?
case 1:
search for last timestep with xa < ya:
    xa + x*reocc <= ya
<=>           x  <= (ya-xa)/reocc
<=>           x  = btm((ya-xa)/reocc)
<=>           x  = (ya-xa)/reocc  [for integers]
and manually check, if xa + x*reocc == ya.
If not: check ya - xa < xb - xa ? (then overlap with x).
case 2:
search for first timestep with xa >= ya:
    xa + x*reocc >= ya
<=>           x  >= (ya-xa)/reocc
<=>           x  = ceil((ya-xa)/reocc)
<=>           x  = (ya-xa+1)/reocc  [for integers]
        check xa < yb ?

Always use SI units or other units, if possible and not clear from context.
This does also include generics.

Good Abstraction: Criteria
- common?
- useful?
- restrictions?
- coupling?
- composable?
Good Abstraction: How?
* bottom-up design: start with application code to inform lib
* null hypothesis: dont use a lib, then develop one


Github issues
```
PID=$(pgrep PROGRAM) && sudo -E capsh --caps="cap_setpcap,cap_setuid,cap_setgid+ep cap_sys_ptrace+eip" --keep=1 --user="$USER" --addamb="cap_sys_ptrace" --shell=/usr/bin/gdb -- -p $PID
thread apply all backtrace full |& tee backtrace.log
```
<details>

```

```

</details>

  max_step typical MAX/8
   |   |
|  m1  m2      |
0              MAX
wraparound counter with limited step length assumption of
assume: correct + continuous connection + value retrieval
6 cases:
* m1 = m2 => 1. no change
* m1 < m2
  * m2 - m1 < max_step => 2. plus
  * MAX-m2+m1 < max_step => 3. wraparound_minus
  * otherwise => 6. unclear
* m2 < m1
  * m1 - m2 < max_step => 4. minus
  * MAX-m1+m2 < max_step => 5. wraparound_plus
  * otherwise => 6. unclear

1. extended_counter = extended_counter;
2. extended_counter += (m2 - m1)
5. extended_counter -= (MAX-m2+m1+1)
4. extended_counter -= (m1 - m2)
3. extended_counter += (MAX-m1+m2+1)
6. extended_counter = extended_counter;

Explanation:
  |  m1        m2      |
  0                   MAX
1    |---------|
2 ---|         |--------
  |  m2        m1      |
  0                   MAX
3    |---------|
4 ---|         |--------

https://fgiesen.wordpress.com/2021/08/30/entropy-coding-in-oodle-data-huffman-coding/
TODO processor performance characteristics 20240528

Performance
System Call Hook for ARM64 for trusted code https://github.com/retrage/svc-hook
System Call Hook for Linux for trusted code https://github.com/yasukata/zpoline

Sane ownership options for multi-threaded code:
* 1. slowest mutex guard
* 2. faster via atomic shared_ptr
* 3. ^v tradeoffs
     * latency/deadline/determinism
     * contention
     * recognition order of memory loads and stores
* 4. very fast via each thread working on own copy of data and efficient merging strategy
* 5. fastest via independent workable and fully saturable non-deadline bound
  structures and/or racy reads and writes into preallocated space are permitted
  due to not leading to inconsistent program state
  * data only marked as visited and order of execution does not affect correctness,
  * example: Paralel Seeded Region Growing

Generally
* Pooling and encoding of data and touching less cache lines faster
* Less contention decreases synchronization cost
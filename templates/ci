Purpose of Continous Integration [CI]: Remote execution service of configurable
runtime environments[1] with the option to do problem debugging[2] and access
control to prevent, restrict and/or detect hostile takeover (attempts) of
infrastructure through malicious actors[3].
Based on access control and detection and/or design, recovery or system
reproducibility from an as minimal as secure and safe trusted immutable
(bootstrapping) system may be implemented[4].
Concrete CI implementations may then choose different tradeoffs for these
purposes, for example what user interactions the control server allows, if and
how runners are added, what they consist of physically, how and what work is
assigned and synchronized, how data (permissions, configuration, files, source
code) are stored, cached, archived.

1:
reasonable simple/minimal CI
     ┌────────────────────┐
     │    Application   |-│-------------|  CI can cover everything from integratin
   ┌─┘   Minimal system | └─┐    CI     |  to test the hardware up to integration
 ┌─┘     Kernel Setup   |   └─┐         |  with the application (fuzzing,
 │         Hardware     |-----│---------|  symbolic execution etc).
 └────────────────────────────┘
The ideal CI provides reproducible behavior on all developer machines with all
debug tooling being used and accessible to developer on top.
In practice several error classes are not reproducible without target barebone
or more virtualization or more runtime instrumentation being used and
the same reasoning can be applied to hardware testing.

Thus in practice, hardware or code logic of components is tested in isolation,
possibly via simulating I/O and time steps, and the API between components is
tested by testing internal state changes of upper and lower layer.
Full system tests then typically focus on regressions or do state exploration
like fuzzing approaches, because the system context of execution is usually
unreasonable to (en)code, let alone derive.

2:
* retrieval of inputs + outputs to reason about internal state
* log, print, step through or trace via runtime environment (JTAG, GPU, Kernel
  debug interface, etc [ideally time travel debugging])
* reduction (bisecting software versions/commit range, hardware influence,
  software configuration etc)
* compiletime and/or runtime validation

3:
* used source code available on system
* sandboxing to prevent external code/program usage
* assume: trustable system
* assume: full build process understandable
* assume: inputs artifacts trustable

4:
* would ideally check for binary identical state in all offline storage
  * is there no formal protocol/model to enumerate software/hardware memory
    region changes for grub/uefi or at hypervisor level? to poweroff-stateful
    memory, let alone enumerate all stateful memory with devices
  * in practice memory marked as read-only
* requires strong isolation and/or partial/full system reset
* may be part of routine on completely untrusted external input

High level
  https://gregoryszorc.com/blog/2021/04/07/modern-ci-is-too-complex-and-misdirected/
  * single remote code execution as service platform
    + built for servicing both near real time and batch/delayed execution
  * uploading your DAG to an execution service
  * single DAG dictating all build, testing, and release tasks
    + zig build to rule them all
  * make it a lib
  * configuration + debugging customer responsibility
    + why should companies externalize their setup/configuration costs?
    + declarative code simpler to debug, no dedicate yaml code
    + example: debugging nix problems without system knowledge
    + boils down to how to expose descendant processes for debugging
    and tracing them with what static/dynamic granularity
Low level:
- configurable
  * editor|shell|monitor integration for runner systems (local|bare|VM)
  * perf vs security tradeoffs
- showstoppers mutable system ressources create nonreproducible global state
  * for building the objects, libraries and executables
    => allow global ressources access is a security risk
    => set of build time dependencies required to know how to reproduce things
       * either by 1. rebuilding the dependency or 2. getting a system with that lib/kernel/etc version
  * for runnning the executables which are loading the objects, libraries and executables
    => global ressources access is security risk
    => set of runtime dependencies required to know how to reproduce things
- sandboxing control unviable for proprietary systems
- cross-compiling limited for proprietary systems
- qemu has huge attack surface due to hugely untested and complex code

Solutions:
- qemu unfixable
- can we contain qemu ie via rise or sel4?

Below part should be rewritten more densely.

The ideal solution:
- text based configuration, no graphical interface
- separation into controller and runner
- strictly typed, simplified posix shell (very portable)
  * skalib runner (the dude that made s6)?
  * zig build has no sandboxing and neither convenient path hackery + high initial delay
- authentication
- artefact caching interface
  * uri based + authentication or what is the simplest way?
- prevents writes outside the current working directory (on default)
- config changes to file require admin ok
- default logging of common paths to fast debug problems
- remote debugger (gdbserver, unclear what protocols windows supports, windbg)
- remote ssh (ideally via wireguard)
- Mutual exclusive locks on pipelines (for sharing ressouces via network)
- Atomiticity of artifact cache access (per node)
- Process limitation of harware usage

=> build DSL from source + DSL has automatic sandboxing checked via Linter, such
that one only needs to review non-sandboxed parts (authentication cache etc).

blockers:
- simulated: qemu incentives are to not make things simple to configure (support interests)
  * automatize install via scripted setups for all major OSes (MacOS, Linux, Windows)
  * setup external tty in a portable way
  * setup ssh in a portable way
  * setup clipboard in a portable way
  * setup to disable external communication (to setup Kernel as copy-pastable
    local runner) in a portable way
- native
  * Windows security insufficient for untrusted input
- each platform class has its own debugger primitives (ptrace, Windows things)

1. CI is unsolvable without painless setup and tty/ssh access
2. OS virtualization is unsolvable by interests/design
3. Use case trusted input (ok to run on Windows) vs untrusted input (Windows
   must be in VM or runs and other access must be accepted)
4. Cluster configurations like Kubernetes are often for superfluous configurations
   and make deployment unnecessary complex
5. Resource exhaustion attacks (port, memory, cpu, io, network, usage)
   * https://www.baeldung.com/linux/tcp-ip-connections-limit
6. More sophisticated attacks

=> ignore unsolvable parts or let community figure them out and document it
   * native system setup are accepted cost
   * virtualization of systems are custom solutions for custom problems, do not
     specialize for them
   * native code allowed to do everything, so unfiltered unusable on Windows
=> solvable
   * on non-Windows (lower market share)
   * idea: cleanup build scripts via self-restriction (like landlock)
   * idea: own setup for ssh by given configuration
   * idea: reproduce Kernel via config and automatize network install
     * unfeasible due to latency + costs etc
   * idea: https://www.qemu.org/docs/master/system/replay.html

Conclusion: Generally CI is unsolvable and it is simpler to roll your own runner.
idea: "Roll your own runner" framework library as entity component system?
  * very unclear, which development team sizes would have maintenance
    capability and usage reason for bare runner.
  * gh actions uses kubernetes for https://docs.github.com/en/actions/hosting-your-own-runners
    + minikube has antifeature CLA

jenkins
- custom DSL requires still clicking around things
- webhooks are annoying to setup: "Generic Webhook Trigger"
- Groovy Sandbox
- No support for bare checkout without repo in cwd
- No default logging of common paths for common errors (can not find groovy script)
- No model for mutual exclusive locks on pipelines
- No atomiticity of artifact cache access
- Missing process limitation of harware usage

- In Jenkinsfile, check out the main repository in the subdirectory using dir():
dir('subDir') {
    checkout scm
}

Linux setup
TODO from bare to CI:
* base system
* ssh via wireguard + toggle to ssh without wireguard
* control server
* empty user setup

TODO web part of CI:
* container? isolation? seccomp?
* ip/ports, nftables, dns
* advanced isolation (seccomp etc)

TODO evaluate hydra design

experimental idea:
- pure vs impure compilation
  * pure relies on nothing from system to enable full build isolation
  * impure requires system interaction => bad for security
- zig config via ECS
- zig provides the runner except for
  * conflict annotation
  * yet capablities/jailing/isolation
  *
- caching interface?

jenkins syntax
script execution
sh '''

'''
// somecomment

run process as SYSTEM on Windows 11.
https://www.gabsoftware.com/tips/run-cmd-or-any-process-as-system-account-on-windows/
https://www.winhelponline.com/blog/run-program-as-system-localsystem-account-windows/
psexec64 -i -s cmd.exe

unclear how to run process as SYSTEM on Windows 11:
https://serverfault.com/questions/1110848/how-to-run-cmd-exe-using-the-system-account-on-windows-11
Most likely requires to hack things.

Backup: copy JENKINS_HOME directory without cache/ Backup/.

Should not use SYSTEM user on < win11, but Administrator. Ideally Jenkins would
allow do allow checkout with dedicated user account and only (re)move files and
set permissions in another user account for running jobs.

Motivation + Performance, latency and other tuning via cpuset, cgroups etc
https://danluu.com/intel-cat/
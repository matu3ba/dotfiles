CPU functionality and assembly below caches

#### CPU functionality
- AMD Zen dont have a single physical location where each register lives
- AMD Zen use a Register File (RF) and a Register Allocation Table (RAT)
- during vzeroupper the zero bit is set, but rolled back on branch-misprediction causing use-after-free
- RF is shared by everything on the same physical core (including hyperthreads)

Good fuzzing techniques based on https://lock.cmpxchg8b.com/zenbleed.html:
- performance counters
- reverse execution
- oracles from test CPU, ie within simulator
- reset instruction level parallelism
- generate random program and automatically transform it into a serialized one:
```asm
movnti [rbp+0x0],ebx  movnti [rbp+0x0],ebx
                      sfence
rcr dh,1              rcr dh,1
                      lfence
sub r10, rax          sub r10, rax
                      mfence
rol rbx, cl           rol rbx, cl
                      nop
xor edi,[rbp-0x57]    xor edi,[rbp-0x57]
```

#### Assembly
- Integer operations are usually faster than the same-sized float number
- Integer division is slower than the respective float due to higher precision
- There are no SIMD routines for integer division
  * one can use conversion to float instead
  * most of the time one can workaround division

Practical assembly usage https://wiki.gentoo.org/wiki/Hardened/Textrels_Guide

nice linux x64 assembly showing concurrency
https://davidad.github.io/blog/2014/03/23/concurrency-primitives-in-intel-64-assembly/

'ForwardCom: An open-standard instruction set for high-performance microprocessors'
by Agner Fog el al. for non-embedded systems with some interesting ideas:
https://lock.cmpxchg8b.com/zenbleed.html
* 1. designed for non-embedded systems (instructions are typically bigger)
* 2. pic on default => code and data can be relocated independently from another
* 3. no global status flags or status register
* 4. can store constant data in instruction codes
* 5. no microcode
* 6. Function libraries instead of static/dynamic libs usable for both
* 7. calculate the required stack size (non recursive)
  + TODO
* 8. simpler memory management + reduces fragmentation as side effect
  + TODO
* 9. (optimal) register allocation across program modules and function libraries
  + TODO
* 10. strong security features
  + TODO
* 11. standards to establish compatibility between different programming languages and different platforms???
  + TODO
* 12. vector register of variable len
  + TODO
* 13. atomics and cache synchronization???
TODO include feedback from https://github.com/ForwardCom/manual/issues/29

RISC5 looks ideal for embedded systems, where instructions are typically smaller
(addresses, constants, etc).
It even has an instruction for flushing the complete cache + clear internal state.

Interesting ideas
'Efficient virtual cache coherency for multicore systems and accelerators' by Xuan Guo
* TODO

'Branch prediction' by Dan Luu https://danluu.com/branch-prediction/
with hints on state of art speculative branch predictors

'Whats new in new CPUs (microprocessors) since the 80s(microcontrollers) ?'
https://danluu.com/new-cpu-features/
* cache
* tlb
* out of order execution, serialize execution (rdtsc)
* memory/concurrency: use locking or CAS routines, barriers are footguns
  * lock ... to lock memory
* write-back memory as eventually consistent uncachable (UC) memory
  * can be buffered internally and has weaker ordering guarantees than UC
* NUMA with latency differences of thread accessing different sockets
  * chip uses directory for lookup of information
  * up to 128 cores use ring bus for inter chip talk, more must pay for directory
* context switches/syscalls (syscall, sysenter) are expensive
  * >14_000 cycles, 40+ TLB evictions (of 64-entry TLB)
  * use io buffers + batching (io_uring etc or kernel mapped memory (vDSO))
* SIMD for executing instruction on 128,256,512 bit data at once
* power management as race to idle, but microoptimizations often dont generalize
* GPU
  * no branch prediction and no large caches, lower clock speed
  * global (throughput 300-400GB/s), shared (on streaming multiprocessor (SM)) and
    register memory (per thread)
  * single instruction multiple thread on each SM
  * PCIe bus bottleneck due to data moving between CPU and GPU
* Virtualization
* SMT/Hyper-Threading speedup around 25%, less predictable perf, thread gets 60% of perf
* branches unpredictable bad, Haswell mispredict penalty 14 cycles,
  * if branch unpredictable (rare), cmov can be good for perf
* alignment padding of structs not relevant on Haswell
  * dont make things page aligned or otherwise aligned to large boundaries or
    cache perf gets destroyed
* self-modifying code not relevant for perf, because running code requires expensive
  communication between chips l1 instruction caches.
* Trends
  * Partitioning for machine multiplexing of tasks without affecting latency, see ci
  * Transactional Memory and hardware Lock elision begin, xend, xabort
  * Fast IO to bypass CPU completely
  * Hardware accelerators
  * Dark silicon for dedicated tasks

100pm = 1Anstrom, Silicon van der Vaals radius is 200pm. So 2nm are something
in between 10-20 atoms thick depending on configuration etc. Are there data
points that can be extrapolated on knowledge/problem solving of quantum
effects?
https://news.ycombinator.com/item?id=4128208
All of these assumptions are wrong
    An UTC minute is 60 seconds.
    There are always 24 hours in a day.
    Months have either 30 or 31 days.
    Years have 365 days.
    February is always 28 days long.
    Any 24-hour period will always begin and end in the same day (or week, or month).
    A week always begins and ends in the same month.
    A week (or a month) always begins and ends in the same year.
    The machine that a program runs on will always be in the GMT time zone.
    Ok, thatâ€™s not true. But at least the time zone in which a program has to run will never change.
    Well, surely there will never be a change to the time zone in which a program hast to run in production.
    The system clock will always be set to the correct local time.
    The system clock will always be set to a time that is not wildly different from the correct local time.
    If the system clock is incorrect, it will at least always be off by a consistent number of seconds.
    The server clock and the client clock will always be set to the same time.
    The server clock and the client clock will always be set to around the same time.
    Ok, but the time on the server clock and time on the client clock would never be different by a matter of decades.
    If the server clock and the client clock are not in synch, they will at least always be out of synch by a consistent number of seconds.
    The server clock and the client clock will use the same time zone.
    The system clock will never be set to a time that is in the distant past or the far future.
    Time has no beginning and no end.
    One minute on the system clock has exactly the same duration as one minute on any other clock
    Ok, but the duration of one minute on the system clock will be pretty close to the duration of one minute on most other clocks.
    Fine, but the duration of one minute on the system clock would never be more than an hour.
    It will never be necessary to set the system time to any value other than the correct local time.
    Ok, testing might require setting the system time to a value other than the correct local time but it will never be necessary to do so in production.
    Time stamps will always be specified in a commonly-understood format like 1339972628 or 133997262837.
    Time stamps will always be specified in the same format.
    Time stamps will always have the same level of precision.
    A time stamp of sufficient precision can safely be considered unique.
    A timestamp represents the time that an event actually occurred.
    Human-readable dates can be specified in universally understood formats such as 05/07/11.

Some more falsehoods:

1. Time never goes backwards (as other people have pointed out, time zones break this).
2. UTC time does not go backwards: Leap seconds are implemented as a minute with 61 seconds.
   * The value returned by POSIX time(3) can go backwards (with sub-second precision).
3. The system boot time never changes. On most platforms, the current time is defined as "boot time plus uptime", and setting the current time is performed by changing the boot time.
4. System uptime never goes backwards. Some platforms handle setting the current time by changing the system uptime.
5. POSIX's CLOCK_MONOTONIC never goes backwards. On some platforms and virtualization environments this can break with CPUs shared between virtual machines.
6. On systems without virtualization, CLOCK_MONOTONIC never goes backwards. On some platforms this can occur due to clock skew between CPUs.

tldr;
- use ISO 8601 TZ, because there is no more compact alternative to TAI yet
- bear in mind that 'unix time' can 1. be simple uptick clock, 2. synchronized with utc or 3. be configured as TAI
- check for TAI configuration on the system, see https://en.wikipedia.org/wiki/Unix_time#Variant_that_counts_leap_seconds
- consider use of CLOCK_BOOTTIME
- time steps are increased and decreased to prevent introduction of leaps
- leap seconds are discrete jumps, so strictly speaking one needs to record 1. timestamp and 2. known leaps to
ensure that leap seconds are correctly taken into account, if one uses any string interpretation
- 'Precision Time Protocol' is used to synchronize timestamps to 'International Atomic Time' or 'Coordinated Universal Time'
- 'Terrestrial Time' is the idealization used for 'International Atomic Time'
- time is relative, so all time data must be seen in the appropriate context

There is no portable api to check Kernel time configurations, so if needed you need
to 1. setup your own Kernels xor 2. provide your own time synchronization network
and accept + handle offline inaccuracies and leap seconds yourself.

UTC timestamp -> unix time conversion for size and speed from
https://blog.reverberate.org/2020/05/12/optimizing-date-algorithms.html

https://www.timescale.com/blog/time-series-compression-algorithms-explained/
time compression algorithms
Integer compression:
* Delta encoding
* Delta-of-delta encoding
* Simple-8b
* Run-length encoding
Floating point compression:
* XOR-based compression
Data-agnostic compression:
* Dictionary compression

NTP notsoprecise time protocol
* millisecond accuracy
PTP precision time protocol
* used in video,
* nanosecond accuracy
* V1,V2,V2.1, gPTP
* time transmitter, leader(master) and time receiver, follower(slave)
* global time source(s) of transmitter
  - GNSS (GPS, Galileo, GLONASS, BeiDou)
* time: TAI (Temps Atomic International)
  - UTC+37s (2025)
  - leap day february 29
  - lep seconds with last 2016-12-31
* 2/3c for cupper cable speed of electricity
  - 0-650ns offset to actual time
* messages compute the delay from round-trip time
* time jumps must not occur
* 5 challenges
  - jitter
    + solution: PTP hardware support in switches: knows latency of passing packets and updates
      correction field of PTP messages
      => 20-90ns offset
      => follow-up message/field for switch packet processing time
    + AVB Milan mandates PTP in switches, Dante, AES67, SMPTE 2110 not, but can benefit
  - asymmetries
    + solution1: dispersion compensation units (only in WANs)
      - dont work well
    + solution2: no asymmetric links, manual asymmetry compensation in switches
      - depends on layer 1 topology, not implemented by many vendors
  - scalability
    + every time receiver communicates with time transmitter
      - delay request and respone => lots of messages => lots of work for time transmitter
      - can even cost licenses
    + solution: PTP boundary clock (BC)
      - give switches option to act as time transmitter to other devices
      => scalable
  - who's time transmitter?
    + every potential grandmaster sends advertisement for itself and devices listen to
      each other
    + priority is set on device itself and vendor hardcores priority, so device
      can take over internet leading to packet drops, when being connected
    + solution1: generate message with priority 0
    + solution2: PTP role master
      - primary time transmitter to block messages
  - security
    + every device can send announce messages
    + some bounary clock switches have static interface roles implemented (port role=master)
    + no announce & sync messages are accepted on that port
    => follow-up message can be attacked
* problems
   * bugs like behavior on reboot
   * pre/post queue hw timestamping (jitter stability)
   * oscillator quality (stability and precision of clock)
   * interface (support across all interfaces or only some)
   * security features (port role master etc)
   * scalability (max msg handling capacity)
   * PTPv1 support (legacy compatibility)
   * VLAN limitations (eg only works on single VLAN)
   * MLAG/vPC (compat with multi-chassis link aggregation)
   * special conditions
   * end devices (jitter tolerances, bmca across multiple interfaces, PTPv1)
   * GNSS (jamming by transmitting interferences, spoofing via counterfeit GNNS signals appearing valid)
   * PTP profiles (unicast/multicast, layer2/3, message rates)
* large scale possible, hw support essential, precise time => must verify + monitor
* normal version +-20ns, but can be done to last digit ns
* Linux has PTP stack to read out packets timestamps before processing in Linux
  * Intel 2-10 can do this
  * DIXP needs it?
* crypto PTP for timestamps going on
* human observable time difference of sound: nanoseconds area
=> processing time addition in switch works like field-bus techniques

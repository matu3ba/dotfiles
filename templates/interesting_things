1. Hardware with CXL allows NIC to move data into main system-memory and
participate in the CPU's cache coherency protocol. The access times for a NIC
to cross the bus to main memory are a smidge slower than CPU->RAM access times.
The v2 of CXL is faster.
Stolen from https://github.com/ziglang/zig/issues/8224#issuecomment-1296068792.

2. Tracking parser state in editor for incremental compilation or verification.
Optimal incremental compilation needs to show more breakthroughs, ie on
feasability, portability and maintainability (Zig).
Optimal incremental verification requires a simple to parse language grammar
for incremental parsing. This needs some degree of language support (simple to
parse grammar like LL(1)/LL(k) etc).
Other use cases are optimal editor language support.

3. Linux/Posix design flaws are already explained in a detailed way, for
example in this 3 article series https://lwn.net/Articles/411845/, from which
clone() is unfixed, unix signals often still have no workarounds (kill is still
racy unless via parent process or pid 1, using reaper process for reliably
killing is hacky) and, as far as I understand, the Unix permission model blocks
things like deeply nested overlay filesystems (to replace the semi-aweful path
hackery nix/guix uses for reproducible builds with overlays, see
https://blog.wesleyac.com/posts/the-curse-of-nixos for inspiration blocked by
design).
More personally, I think most Kernels are not designed with a test concept to
ensure correctness in mind, which would include cross-compilation + simulation
in Kernel land.
3.1. clone(): either expose all the process details including version
incompatibilities or none of it. In between is always halfbaked. Scope?
3.2. signaling: pid+uid or anything to make it unique + (reliable pid lookup +
action via criteria)
3.3. file permissions: new design + Kernel rewrite

4. Risc V might provide a solution to timing channel attacks by fence.t, see
here for a short technical discussion
https://www.reddit.com/r/RISCV/comments/10i6hwb/preventing_timing_channels_eg_spectre_with_fencet/.
In short, clearing valid cache bits not enough, because cache has secondary
state (state machine controlling cache-line replacement). For their example,
they get over-head of about 0.2%, but indirect costs for applications was not
evaluated (used L3 cache very small). Fetching is ~90ns access cost from RAM,
but it woudl be unclear what should be fetched and out-of-order execution with
speculative fetching was not used. The other more intersting instruction set
ForwardCom (more high level without microcode) has to my knowledge neither a
good solution to this performance problem yet.

5. Atomic memory reordering semantics: Out of thin air problem is probably
known, so I am still curious how the hardware exactly works with possible
(minimal, maximal) timings, why global and local optimizations affect another
and why nobody has explained this in an understandable way outside of academic
papers.

6. Pointer semantics is based on Separation logic (extension of Hoare Type
Theory with associated aliases), so instead of "update the value", "update the
value for all associated aliases". I am wondering, why, if Rust can use them
for a memory model of their borrow checking semantics, it is still unsettled in
LLVM blocking CHERI upstreaming (mixed tagged pointer capabilities) and full
restrict support.

7. Motivation for (big) projects
* can be difficult to stay motivated and complete large technical projects
* break down large tasks in chunks that result in seeing tangible forward progress (SMART goals)
* one approach: continuously see real results to order work based on that
  - goal: make a good demo summarizing work so far (and next work) FOR YOURSELF.
* my approach: clarify design to see the (long-term) beauty of the approach/implementation
* other approach:

Realization of 2 as software motivation and 4 as more hardware-related
motivation.
- Design to realize and ensure quality
  * system design (inialization, deinialization, system debugging/tracing,
  parallelism, memory access etc)
  * test design
  * time estimations
  * possible application methods
  * optimization methods with tradeoffs
- Market estimation
  * would be nice to improve on non-technical side
  * technical estimations have never been a problem
- Realization
  * communication efficiency
  * tooling understanding, design and development
  * motivation techniques and options

more widely usable benefits of (optimal) incremental compilation
- linker library
- debugger abstractions (ptrace)
- strategy/tooling to detect reproducible race conditions?

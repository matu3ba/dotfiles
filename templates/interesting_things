shadow archives (sci-hub) for papers etc https://annas-archive.org

1. Hardware with CXL allows NIC to move data into main system-memory and
participate in the CPU's cache coherency protocol. The access times for a NIC
to cross the bus to main memory are a smidge slower than CPU->RAM access times.
The v2 of CXL is faster.
Stolen from https://github.com/ziglang/zig/issues/8224#issuecomment-1296068792.

2. Tracking parser state in editor for incremental compilation or verification.
Optimal incremental compilation needs to show more breakthroughs, ie on
feasibility, portability and maintainability (Zig).
Optimal incremental verification requires a simple to parse language grammar
for incremental parsing. This needs some degree of language support (simple to
parse grammar like LL(1)/LL(k) etc).
Other use cases are optimal editor language support.

3. Linux/Posix design flaws are already explained in a detailed way, for
example in this 3 article series https://lwn.net/Articles/411845/, from which
clone() is unfixed, unix signals often still have no workarounds (kill is still
racy unless via parent process or pid 1, using reaper process for reliably
killing is hacky) and, as far as I understand, the Unix permission model blocks
things like deeply nested overlay filesystems (to replace the semi-awful path
hackery nix/guix uses for reproducible builds with overlays, see
https://blog.wesleyac.com/posts/the-curse-of-nixos for inspiration blocked by
design).
More personally, I think most Kernels are not designed with a test concept to
ensure correctness in mind, which would include cross-compilation + simulation
in Kernel land.
3.1. clone(): either expose all the process details including version
incompatibilities or none of it. In between is always halfbaked. Scope?
3.2. signaling: pid+uid or anything to make it unique + (reliable pid lookup +
action via criteria)
3.3. file permissions: new design + Kernel rewrite

4. Risc V might provide a solution to timing channel attacks by fence.t, see
here for a short technical discussion
https://www.reddit.com/r/RISCV/comments/10i6hwb/preventing_timing_channels_eg_spectre_with_fencet/.
In short, clearing valid cache bits not enough, because cache has secondary
state (state machine controlling cache-line replacement). For their example,
they get over-head of about 0.2%, but indirect costs for applications was not
evaluated (used L3 cache very small). Fetching is ~90ns access cost from RAM,
but it would be unclear what should be fetched and out-of-order execution with
speculative fetching was not used. The other more interesting instruction set
ForwardCom (more high level without microcode) has to my knowledge neither a
good solution to this performance problem yet.

5. Atomic memory reordering semantics: Out of thin air problem is probably
known, so I am still curious how the hardware exactly works with possible
(minimal, maximal) timings, why global and local optimizations affect another
and why nobody has explained this in an understandable way outside of academic
papers.

6. Pointer semantics is based on Separation logic (extension of Hoare Type
Theory with associated aliases), so instead of "update the value", "update the
value for all associated aliases". I am wondering, why, if Rust can use them
for a memory model of their borrow checking semantics, it is still unsettled in
LLVM blocking CHERI upstreaming (mixed tagged pointer capabilities) and full
restrict support.
* LLVM unable to formalize frontend/programmer control to workaround performance
costs.
* Own assumption: Default fixes with big performance costs xor compilation time costs
and nothing important broke horribly yet.

7. Motivation for (big) projects
* can be difficult to stay motivated and complete large technical projects
* break down large tasks in chunks that result in seeing tangible forward progress (SMART goals)
* one approach: continuously see real results to order work based on that
  - goal: make a good demo summarizing work so far (and next work) FOR YOURSELF.
* my approach: clarify design to see the (long-term) beauty of the approach/implementation
* other approach:

Realization of 2 as software motivation and 4 as more hardware-related
motivation.
- Design to realize and ensure quality
  * system design (initialization, deinialization, system debugging/tracing,
  parallelism, memory access etc)
  * test design
  * time estimations
  * possible application methods
  * optimization methods with tradeoffs
- Market estimation
  * would be nice to improve on non-technical side
  * technical estimations have never been a problem
- Realization
  * communication efficiency
  * tooling understanding, design and development
  * motivation techniques and options

more widely usable benefits of (optimal) incremental compilation
- linker library
- debugger abstractions (ptrace)
- strategy/tooling to detect reproducible race conditions?

State of WASM in 5 years.
Why? Plugins to software, cheap sandboxing. Build once, run everywhere VM
without bloat.

https://www.forcepoint.com/fr/blog/x-labs/webassembly-potentials-and-pitfalls
1. So far there have not been major attacks against wasm VMs, so I guess we are
not yet at the major adoption state.
2. Integrity checks of bytecode are unsolved from what I understand.
3. Cross-compiling broken logic has not been identified as potential major
problem.
4. web assembly abi is too unspecified for reusable components, aka many  java
use cases: as example, exit codes are a boolean and provide too few conventions
how to communicate exit information with the platform (one option would be to
read from annotated memory segments), see https://github.com/WebAssembly/wasi-cli/issues/11
5. reverse execution and other debugging techniques are not exploited yet from
deterministic execution, although it is extremely powerful, see rr/time travel
debugging, see https://github.com/WebAssembly/design/blob/main/Nondeterminism.md

Main thing is that you cant scale wasm arbitrarily, because at some point you
are getting bugs and replaying them in a distributed system can be extremely
challenging, so you want all the tools available, which you have for native
applications. So once 4 and 5 are more solved, you will see major adoption, but
for 5 probably somebody needs to step up with (reverse) debugging support.
